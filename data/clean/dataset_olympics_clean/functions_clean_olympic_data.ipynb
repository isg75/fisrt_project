{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1ab74e-7812-46de-904f-fad6f58ce8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "olympic_data=pd.read_csv('athlete_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb405adc-e2d9-4f41-ac89-e72ed157011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of countries and athletes participating is inconsistent before 1996 - use only data post 1996\n",
    "condition_year_1996=olympic_data[\"Year\"]>=1996\n",
    "olympic_data=olympic_data[condition_year_1996]\n",
    "condition_summer=olympic_data[\"Season\"]==\"Summer\"\n",
    "olympic_data=olympic_data[condition_summer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac321a-8e79-422e-8973-dcc3dd24cc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping dictionary for corrections\n",
    "# Replace incorrect names with correct ones\n",
    "\n",
    "corrections = {\n",
    "    \"Athina\": \"Athens\",\n",
    "    \"Roma\": \"Rome\",\n",
    "    \"Moskva\": \"Moscow\",\n",
    "    \"Sankt Moritz\": \"St. Moritz\"\n",
    "}\n",
    "\n",
    "\n",
    "olympic_data['City'] = olympic_data['City'].replace(corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a25091a-32df-4a21-aefb-41809c47c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigating quality of ID column\n",
    "#Duplicates exist but this is intentional, as one athlete can participate in more than one event/olympics.\n",
    "#ID numbering is consistent throughout years - e.g. same ID for athlete in different olympic games.\n",
    "#ID is based on alphabetical order of last name\n",
    "#no missing values in the ID column\n",
    "#Team column comments: Team names are inconsistent - mixed with countries and sports team names. We will use NOC column instead for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227d41c-5686-4895-b4b8-f39693cd83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace Na values as \"No Medal\" string as null values correspond to no winning athletes.\n",
    "olympic_data[\"Medal\"] = olympic_data[\"Medal\"].apply(lambda x:\"No Medal\" if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73c5f7-f382-498e-a792-b28193ceec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The difference between the medal count can be due to differences on the number of team sport members and ties.\n",
    "olympic_data[\"Medal\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6304e-eba7-470e-8b6e-7fa8c780f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_data.drop_duplicates(inplace = True)\n",
    "print(olympic_data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc5224b-bfb4-41ec-9874-27895a6aa2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deduplicating the number of medals from team sports\n",
    "#Creat a dataframe just with the result of each olympic by event (Gold, Silver and Bronze)\n",
    "olympic_data[\"Concat\"]=olympic_data[\"Games\"] + olympic_data[\"Event\"] +olympic_data[\"Medal\"]+olympic_data[\"NOC\"]\n",
    "olympic_data_podium=olympic_data[olympic_data[\"Medal\"]!= \"No Medal\"]\n",
    "olympic_data_podium.drop_duplicates(subset=[\"Concat\"], inplace= True)\n",
    "olympic_data_podium.Concat.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526d611-40c2-4610-8c52-df95c9ea03ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat a new file droping teams duplicated\n",
    "#Create a new dataframe\n",
    "olympic_data_not_duplicated=olympic_data\n",
    "olympic_data_not_duplicated[\"Concat\"]=olympic_data_not_duplicated[\"Games\"] + olympic_data_not_duplicated[\"Event\"] +olympic_data_not_duplicated[\"Medal\"]+olympic_data_not_duplicated[\"NOC\"]\n",
    "olympic_data_not_duplicated.drop_duplicates(subset=[\"Concat\"], inplace= True)\n",
    "olympic_data_not_duplicated.Concat.duplicated().sum()\n",
    "\n",
    "#NOC column - we want to merge the NOC column in our Olympics dataset with the region column from the NOC regions dataset\n",
    "noc_regions = pd.read_csv('noc_regions.csv')\n",
    "\n",
    "#Merge with NOC\n",
    "olympic_data_not_duplicated= pd.merge(\n",
    "    olympic_data_not_duplicated, \n",
    "    noc_regions[['NOC', 'region']], \n",
    "    on='NOC', \n",
    "    how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7a434-3d4f-48b7-b49a-6a9b3b027589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOC column - we want to merge the NOC column in our Olympics dataset with the region column from the NOC regions dataset\n",
    "noc_regions = pd.read_csv('noc_regions.csv')\n",
    "\n",
    "#Merge the datasets on the 'NOC' column\n",
    "olympics_updated = pd.merge(\n",
    "    olympic_data_podium, \n",
    "    noc_regions[['NOC', 'region']], \n",
    "    on='NOC', \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c682aa-108f-451f-9093-fcd946616742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "olympic_data_not_duplicated.to_csv('teams_not_duplicated_summer_olympics_1996-2016_deduplicate_team_medals.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
